{"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"BB3 Site Separator\nWritten by Sebastian DiGeronimo\n\n**Important**\nThis script should read a BB3 file that contains many stations (sometimes many cruises) and separate them into stations. The file format is MBON_MM_DD_YYYYTHHmmss_site_ID (i.e MBON_07_01_20T183009_site_KW2). \n\nI've tried to circumvent errors by adding exceptions to the list, some examples of errors:\n* 01/07/20\t10:25:31\t470\t118\t532\t128\t650\t170\t536\n  01/07/20\t10:25:32\t470\t115\t532\t147\t65:34\t470\t115\t532\t136\t650\t201\t536 <-- error\n\n* 01/07/20\t10:25:59\t470\t120\t532\t200\t650\t165\t534 \n  01/07/20\t1:00\t470\t132\t532\t196\t650\t450\t534 <-- error\n  \n* 01/07/20\t10:26:52\t470\t113\t532\t127\t650\t159\t532\n  01/07/20\t107/20\t10:26:56\t470\t124\t532\t127\t650\t155\t532 <-- error\n  \n* 01/07/20\t10:27:19\t470\t107\t532\t145\t650\t236\t532\n  01/07/20\t10:27:20\t470\t110\t532\t <-- error\n \n* 01/07/20\t11:34:51\t470\t54\t532\t80\t650\t364\t536\n  01/07/20\t1132\t82\t650\t362\t536 <-- error\n  \n* 01/07/20\t11:36:12\t470\t92\t532\t102\t650\t118\t533\n  0\t650\t149\t534 <-- error\n  \nSome problems I don't know how to solve is if the time stamp jumps by more than 5 min thus creating a new station file, when the line after goes back to the previous file:\n01/07/20\t11:36:36\t470\t91\t532\t92\t650\t113\t533\n01/07/20\t11:46:37\t470\t91\t532\t98\t650\t110\t533 <-- this will create a new file, even though its just an error \n01/07/20\t11:36:38\t470\t92\t532\t94\t650\t108\t532","metadata":{},"id":"198bbda1"},{"cell_type":"code","source":"from datetime import timedelta\nfrom datetime import datetime\nimport os\nfrom parse import parse\nfrom IPython.display import display\nimport pandas\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"a5d2dfa1"},{"cell_type":"markdown","source":"**Definitions** ","metadata":{},"id":"146c6677"},{"cell_type":"code","source":"# to check if a file path for a cruise exist already, if not will make one\ndef ensure_dir(file_path):\n    directory = os.path.dirname(file_path)\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n# checks if a value is able to be converted to float, else NaN        \ndef my_conv(x): \n    try: \n        return np.float64(x)\n    except ValueError: \n        return np.nan","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"b796ba5d"},{"cell_type":"markdown","source":"You may customize the folder of input, usually should be a cruise ID (i.e. WS18256 for Walton Smith 2018 Julian Day)","metadata":{},"id":"c62ea899"},{"cell_type":"code","source":"# folder_cust = input(\"do you want a custom folder name (yes|y|YES)? (default is BB3/)\")\n# if folder_cust == \"yes\" or folder_cust == \"y\" or folder_cust == \"YES\":\n#     folder_name = input(\"what do you want directory to be?\") + '/'\n# else:\n#     folder_name = 'BB3/'        # comment out if want to costumize folder\n# ensure_dir(folder_name)\n\nfolder_name = 'BB3/'        # comment out if want to customize folder\nensure_dir(folder_name)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"dbe3810f"},{"cell_type":"markdown","source":"This allows you to choose a file to run. \n**This could be improved by having it search all files in a directory within the else statement** Currently, you need can put in file *a prior*","metadata":{},"id":"f77f7e57"},{"cell_type":"code","source":"# choose_file = input(\"do you want a specific file ran (yes|y|YES)?\")\n# if choose_file == \"yes\" or choose_file == \"y\" or choose_file == \"YES\":\n#     FILEPATH = input('Whats the file path?')\n# else:\n#     FILEPATH = 'WS20006_full_download.raw'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"ac7038c9"},{"cell_type":"markdown","source":"Read a file","metadata":{},"id":"406930b0"},{"cell_type":"code","source":"FILEPATH = \"../../data/WS19266_BB3.raw\"\n\n# sets datetime as month/day/year hour:minute:second (i.e 7/25/2018 13:35:23)\ndt_fmt = \"%m/%d/%y  %H:%M:%S\"\n\n# read the tab-separated-values file (`.raw` = `.tsv`)\nbb3_df = pandas.read_csv(\n    FILEPATH, \n    sep='\\s+',\n    on_bad_lines='skip',  # default is 'error'. can also use 'warn' and 'skip'\n    names=[\"date\",\"time\",\"470nm\", \"470nm_data\",\"532nm\", \"532nm_data\", \"650nm\", \"650nm_data\", \"therm\"],\n    skiprows=1,\n    # na_filter = 'TRUE',\n    # TODO: use more features to better filter\n    converters={\"470nm\":my_conv, \"470nm_data\":my_conv,\"532nm\":my_conv, \"532nm_data\":my_conv, \"650nm\":my_conv, \n           \"650nm_data\":my_conv, \"therm\":my_conv},  # this should fix a lot\n    parse_dates = {'dt':[\"date\", \"time\"]}  # this should parse the two columns together as one datetime\n)\n\n# convert datetime column to type datetime[ns], will convert non-match to NaT\nbb3_df['dt']= pandas.to_datetime(\n    bb3_df['dt'], \n    errors = 'coerce',\n    format = dt_fmt,\n    exact = True\n) \n\n# drop rows with NaN or NaT, this will remove any rows with bad datetimes \nbb3_df = bb3_df.dropna()\n\n# convert the dt col from string to datetime object\nbb3_df.index = bb3_df.dt\n\n#---------------------------------------------------------------------\n# index for values being wavelengths of 470, 532 or 650 nm\nidx = (\n    (bb3_df['470nm'] == 470) & \n    (bb3_df['532nm'] == 532) & \n    (bb3_df['650nm'] == 650)\n)\n\nbb3_df = bb3_df.loc[idx,:]\n\n# # drop useless columns\nbb3_df.drop(['dt','470nm', '532nm', '650nm'], axis=1, inplace = True)\n\n#---------------------------------------------------------------------\n# === filter out data outside known bounds of 12-bit sensors\n#TODO: filter out the out-of-bounds data\n\n# bb3_df.to_csv(\"test.csv\", sep = '\\t', index=True)\n\n# now you can use the pandas dataframe\nSEPARATOR = \"=\"*100  # this creates big string like `=====================` with 302 `=` characters\ndisplay(SEPARATOR)\ndisplay(bb3_df.describe())\ndisplay(SEPARATOR)\ndisplay(bb3_df.info())\ndisplay(SEPARATOR)\ndisplay(bb3_df)","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"931a5644-8fe1-479a-a797-76990d44a87b"},{"cell_type":"code","source":"bb3_df.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"8ee4f678-f237-4e50-9d26-e612abb73a80"},{"cell_type":"code","source":"print('\\n\\npost-drop & convert:')\ndisplay(bb3_df_clean.describe(include='all'))\ndisplay(bb3_df_clean.info())\n\n# === filter out data outside known bounds of 12-bit sensors\nSENSOR_MIN = 0\nSENSOR_MAX = 4095\nbb3_df_clean = bb3_df_clean[\n    (bb3_df_clean['470nm_data'] > SENSOR_MIN) &\n    (bb3_df_clean['470nm_data'] < SENSOR_MAX) &\n    (bb3_df_clean['532nm_data'] > SENSOR_MIN) &\n    (bb3_df_clean['532nm_data'] < SENSOR_MAX) &\n    (bb3_df_clean['650nm_data'] > SENSOR_MIN) &\n    (bb3_df_clean['650nm_data'] < SENSOR_MAX) &\n    (bb3_df_clean['mystery_column'] > SENSOR_MIN) &\n    (bb3_df_clean['mystery_column'] < SENSOR_MAX)\n\n]\nprint('\\n\\npost-bounds filter:')\ndisplay(bb3_df_clean.describe(include='all'))\n\n\n\nbb3_df_clean.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"3d9b1963-59ae-427e-96ff-f1f5929fd87c"},{"cell_type":"markdown","source":"## Don't Use ##\nwill be useful later","metadata":{},"id":"a9c209b9-ce75-4eb5-a45b-8ea0086a8e1c"},{"cell_type":"markdown","source":"This sets the format of the datatime that is read in from the file as well as other parameters for later","metadata":{},"id":"af6167fe-6881-41c7-96ec-fe70a4e4187d"},{"cell_type":"code","source":"# is a place holder to use the previous date to check against\ndt_prev = \"\"\n\n# place holder for the file name to be created if has not a read a new station\nfile_name = ''\n\n# format to read each line to check for datetime due to errors in lines when downloading\n# if does not match this will ignore that line\nline_fmt = (\n    '{:2d}/{:2d}/{:2d}\t{:2d}:{:2d}:{:2d}\t'\n    '{:3d}\t{:4d}\t{:3d}\t{:4d}\t{:3d}\t{:4d}\t{:3d}'\n)","metadata":{},"execution_count":null,"outputs":[],"id":"29f23b1d-9f3a-4b45-8d39-ec4639d3b360"},{"cell_type":"code","source":"# use readline() to read the first line\nline_of_text = f.readline()\n\nwhile line_of_text:\n        parsed_line = parse(line_fmt, line_of_text)\n        # print(parsed_line)\n        # this checks if the date is in correct format, assumes data will be correct if date is\n        try:\n            time_of_sample = \"{}/{}/{} {}:{}:{}\".format(\n                parsed_line[0], parsed_line[1], parsed_line[2],\n                parsed_line[3], parsed_line[4], parsed_line[5]\n            )\n            dt = datetime.strptime(time_of_sample, dt_fmt)\n        except Exception:  # the errors involves looping the error 46 times, then continuing\n            #print(time_of_sample)\n            # puts error lines into a file\n            error_file = open('files_with_errors.txt', \"a\")\n            error_file.write(line_of_text)\n            line_of_text = f.readline()\n            continue\n\n        # if open dt_prev, will take current dt and subtract 1 sec to use a comparison\n        if dt_prev == \"\":\n            dt_prev = dt - timedelta(seconds=1)\n        dt_current = dt\n\n        # checks to make sure time is not negative, would mean error \n        #(i.e. if subtract 2 times and the results is negative time, 1:00:00 - 2:00:00 = -1:00:00)\n        \n        # TODO: make a way to check the next two to see if the time difference goes back down\n        #  an error where the time will jump up more than 10 minutes but then jump back down,\n        #  so starts to create another file, but then the time is negative (IGNORE if doesn't make sense)\n        if dt_current - dt_prev < timedelta(milliseconds=0):\n            print(dt_current, dt_prev) # shows the time of error and will help with diagnosing later\n            error_file = open('files_with_errors.txt', \"a\")\n            error_file.write(line_of_text)\n\n            line_of_text = f.readline()\n        \n        # will look at one line by line to see if they are 5 mins apart. I assume that if > 5 mins will be a new site\n        elif dt_current - dt_prev < timedelta(minutes=5):\n            # for the next iteration, sets current to prev\n            dt_prev = dt_current\n            \n            # if file name for a station does not exist will create one where you can input the station name\n            if file_name == \"\":\n                i = dt_current.strftime(\"%d_%m_%yT%H%M%S\")\n                # this is so can look up timestamp on spreadsheet and label site\n                print('Old time: ' + str(dt_current))\n                # edit in later, to name site during run\n                site = input(\"What is the site ID?\")\n                file_name = 'MBON_{}_site_{}.txt'.format(i, site)\n                newfile = open(folder_name + file_name, \"a\")\n                newfile.write(line_of_text)\n            else:\n                newfile = open(folder_name + file_name, \"a\")\n                newfile.write(line_of_text)\n                \n        # if >5 mins will allow a new start for a new station\n        else:\n            dt_prev = dt_current\n            i = dt_current.strftime(\"%d_%m_%yT%H%M%S\")\n            # this is so can look up timestamp on spreadsheet and label site\n            print('Old time: ' + str(dt_current))\n            # edit in later, to name site during run\n            site = input(\"What is the site ID?\")\n            #site = site + 1         #edit out later\n            file_name = 'MBON_{}_site_{}.txt'.format(i,site)\n            newfile = open(folder_name + file_name, \"a\")\n            newfile.write(line_of_text)\n        line_of_text = f.readline()\nf.close()","metadata":{},"execution_count":null,"outputs":[],"id":"4e821f72"}]}